{
  "pose_dim": 258,
  "vocab_size": 100,
  "max_seq_length": 150,
  "d_model": 512,
  "nhead": 8,
  "num_encoder_layers": 6,
  "dim_feedforward": 2048,
  "dropout": 0.1,
  "activation": "gelu",
  "layer_norm_eps": 1e-05
}