================================================================================
GLOSS SELECTION DEBUG REPORT
================================================================================

Dataset: ../../datasets/synthetic_sentences/synthetic_gloss_to_sentence_llm_dataset_50_glosses.json
Total entries: 25
Successful: 25 (100.0%)
Failed: 0 (0.0%)

================================================================================
1. MODEL GLOSS ACCURACY - TOP-1 (Before LLM Selection)
================================================================================
Overall Accuracy: 86/99 (86.9%)
Perfect Predictions (all glosses correct): 14/25 entries (56.0%)
Average Per Entry: 86.8%

================================================================================
2. EFFECTIVE GLOSS ACCURACY (After LLM Selection from Top-K)
================================================================================
Overall Accuracy: 89/99 (89.9%)
Perfect Predictions (all glosses correct): 17/25 entries (68.0%)
Average Per Entry: 90.2%

Improvement from LLM Selection: +3.0% (86/99 -> 89/99)
Perfect Predictions Gained: 3 entries

================================================================================
3. GLOSS SELECTION BREAKDOWN
================================================================================
Total Gloss Positions: 99
Correctly Selected from Top-K: 89 (89.9%)
Incorrectly Selected from Top-K: 10 (10.1%)

================================================================================
4. MISMATCH ANALYSIS
================================================================================
Total Mismatches: 10
  - LLM Selection Errors (correct answer WAS in top-3): 4 (40.0%)
  - Model Prediction Errors (correct answer NOT in top-3): 6 (60.0%)

** POTENTIAL IMPROVEMENT: 4 glosses could be fixed with better LLM prompting **

================================================================================
5. ENTRIES WITH SELECTION ERRORS (Detailed Breakdown)
================================================================================

Entry 2: WOMAN, EAT, APPLE
  Reference: The woman is eating an apple.
  Predicted: The woman is wrong about the apple.
  Selected Glosses: WOMAN, WRONG, APPLE
  Mismatches (1):

    Position 1: [MODEL PREDICTION ERROR]
      LLM Selected: 'WRONG' (WRONG)
      Should Be: 'EAT' (CORRECT)
      Available in Top-3:
        1. wrong (65.2%)
        2. hot (8.4%)
        3. deaf (4.9%)

Entry 3: MOTHER, GIVE, APPLE
  Reference: The mother will give an apple.
  Predicted: Now the mother wants an apple.
  Selected Glosses: MOTHER, NOW, APPLE
  Mismatches (1):

    Position 1: [LLM SELECTION ERROR]
      LLM Selected: 'NOW' (WRONG)
      Should Be: 'GIVE' (CORRECT)
      Available in Top-3:
        1. now (50.7%)
        2. give (40.0%) ← CORRECT!
        3. dog (6.1%)

Entry 7: BOOK, TABLE, NOW
  Reference: The book is on table now.
  Predicted: The book is on the computer now.
  Selected Glosses: BOOK, COMPUTER, NOW
  Mismatches (1):

    Position 1: [LLM SELECTION ERROR]
      LLM Selected: 'COMPUTER' (WRONG)
      Should Be: 'TABLE' (CORRECT)
      Available in Top-3:
        1. computer (71.1%)
        2. table (27.8%) ← CORRECT!
        3. year (0.3%)

Entry 9: APPLE, ORANGE, EAT
  Reference: I will eat apple or orange.
  Predicted: The apple hearing is wrong.
  Selected Glosses: APPLE, HEARING, WRONG
  Mismatches (2):

    Position 1: [MODEL PREDICTION ERROR]
      LLM Selected: 'HEARING' (WRONG)
      Should Be: 'ORANGE' (CORRECT)
      Available in Top-3:
        1. apple (49.6%)
        2. hearing (18.0%)
        3. cool (6.9%)

    Position 2: [MODEL PREDICTION ERROR]
      LLM Selected: 'WRONG' (WRONG)
      Should Be: 'EAT' (CORRECT)
      Available in Top-3:
        1. wrong (65.2%)
        2. hot (8.4%)
        3. deaf (4.9%)

Entry 15: CHAIR, BLACK, NOW, FINE, YES
  Reference: The black chair is fine now, yes?
  Predicted: Now the black chair is like yes.
  Selected Glosses: CHAIR, BLACK, NOW, LIKE, YES
  Mismatches (1):

    Position 3: [LLM SELECTION ERROR]
      LLM Selected: 'LIKE' (WRONG)
      Should Be: 'FINE' (CORRECT)
      Available in Top-3:
        1. like (90.4%)
        2. fine (6.5%) ← CORRECT!
        3. walk (1.7%)

Entry 16: APPLE, ORANGE, EAT, NOW, LIKE, YES, NO
  Reference: I will eat apple or orange now, do you like it, yes or no?
  Predicted: Hearing the apple is wrong now, like yes or no?
  Selected Glosses: APPLE, HEARING, WRONG, NOW, LIKE, YES, NO
  Mismatches (2):

    Position 1: [MODEL PREDICTION ERROR]
      LLM Selected: 'HEARING' (WRONG)
      Should Be: 'ORANGE' (CORRECT)
      Available in Top-3:
        1. apple (49.6%)
        2. hearing (18.0%)
        3. cool (6.9%)

    Position 2: [MODEL PREDICTION ERROR]
      LLM Selected: 'WRONG' (WRONG)
      Should Be: 'EAT' (CORRECT)
      Available in Top-3:
        1. wrong (65.2%)
        2. hot (8.4%)
        3. deaf (4.9%)

Entry 17: MAN, LIKE, APPLE, NOW, WOMAN, LIKE, ORANGE
  Reference: The man likes apple now, but the woman likes orange.
  Predicted: The man and woman like the apple now like the apple.
  Selected Glosses: MAN, LIKE, APPLE, NOW, WOMAN, LIKE, APPLE
  Mismatches (1):

    Position 6: [MODEL PREDICTION ERROR]
      LLM Selected: 'APPLE' (WRONG)
      Should Be: 'ORANGE' (CORRECT)
      Available in Top-3:
        1. apple (49.6%)
        2. hearing (18.0%)
        3. cool (6.9%)

Entry 25: MOTHER, GIVE, APPLE, FORGET, DRINK, NOW
  Reference: The mother is giving an apple, but forgot to drink now.
  Predicted: Mother, give the apple to forget, forget now.
  Selected Glosses: MOTHER, GIVE, APPLE, FORGET, FORGET, NOW
  Mismatches (1):

    Position 4: [LLM SELECTION ERROR]
      LLM Selected: 'FORGET' (WRONG)
      Should Be: 'DRINK' (CORRECT)
      Available in Top-3:
        1. drink (64.5%) ← CORRECT!
        2. forget (21.5%)
        3. cousin (9.1%)



================================================================================
PERFORMANCE METRICS
================================================================================

BASELINE BLEU: 18.36
MODEL BLEU: 38.25
AVERAGE BLEU IMPROVEMENT: +19.89
ENTRIES WITH BLEU IMPROVEMENT: 21/25 (84.0%)
AVERAGE BLEU IMPROVEMENT (of improved entries): +24.77

BASELINE BERTScore: 90.71
MODEL BERTScore: 94.84
AVERAGE BERTScore IMPROVEMENT: +4.12
ENTRIES WITH BERTScore IMPROVEMENT: 21/25 (84.0%)
AVERAGE BERTScore IMPROVEMENT (of improved entries): +5.00

BASELINE QUALITY: 36.94
MODEL QUALITY: 72.08
AVERAGE QUALITY IMPROVEMENT: +35.15
ENTRIES WITH QUALITY IMPROVEMENT: 22/25 (88.0%)
AVERAGE QUALITY IMPROVEMENT (of improved entries): +42.91

BASELINE COVERAGE (vs Reference Sentence):
AVERAGE RECALL: 85.2%
AVERAGE PRECISION: 92.0%
AVERAGE F1: 87.9%
MODEL COVERAGE (vs Reference Sentence):
AVERAGE RECALL: 86.6%
AVERAGE PRECISION: 86.0%
AVERAGE F1: 85.8%
PERFECT RECALL: 14/25 (56.0%)
ENTRIES WITH MISSING WORDS: 11/25 (16 total)
ENTRIES WITH HALLUCINATIONS: 13/25 (14 total)
AVERAGE RECALL IMPROVEMENT: +1.3%
AVERAGE PRECISION IMPROVEMENT: -5.9%
AVERAGE F1 IMPROVEMENT: -2.1%
ENTRIES WITH RECALL IMPROVEMENT: 2/25 (8.0%)

BASELINE COMPOSITE: 57.64
MODEL COMPOSITE: 74.98
AVERAGE COMPOSITE IMPROVEMENT: +17.34
ENTRIES WITH COMPOSITE IMPROVEMENT: 22/25 (88.0%)
AVERAGE COMPOSITE IMPROVEMENT (of improved entries): +20.56

GEMINI ALTERNATIVE USAGE (Top-2 or Top-3 instead of Top-1):
TOTAL GLOSS POSITIONS: 99
ALTERNATIVES USED: 2 (2.0%)
ENTRIES WITH ALTERNATIVES: 2/25 (8.0%)


DETAILED RESULTS:
--------------------------------------------------------------------------------

Entry 1:
  Glosses: MAN, WALK, NOW
  Reference: The man is walking now.
  Predicted: The man will walk now.
  Model Gloss Accuracy (top-1): 3/3 (100.0%)
  Effective Gloss Accuracy (LLM-selected): 3/3 (100.0%)
  Effective Glosses: MAN, WALK, NOW
  Baseline BLEU: 17.80
  Model BLEU: 23.64
  BLEU Improvement: +5.84
  Baseline BERTScore: 94.53
  Model BERTScore: 97.07
  BERTScore Improvement: +2.54
  Baseline Quality: 56.11
  Model Quality: 76.57
  Quality Improvement: +20.47
  Baseline Coverage Recall: 100.0%
  Baseline Coverage Precision: 100.0%
  Baseline Coverage F1: 100.0%
  Model Coverage Recall: 100.0%
  Model Coverage Precision: 100.0%
  Model Coverage F1: 100.0%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: +0.0%
  Coverage F1 Improvement: +0.0%
  Baseline Composite: 69.02
  Model Composite: 78.59
  Composite Improvement: +9.57
  LLM Alternatives Used: 0/3
  Status: success

Entry 2:
  Glosses: WOMAN, EAT, APPLE
  Reference: The woman is eating an apple.
  Predicted: The woman is wrong about the apple.
  Model Gloss Accuracy (top-1): 2/3 (66.7%)
  Top-1 Mismatches:
    Position 1: 'wrong' vs 'EAT'
  Effective Gloss Accuracy (LLM-selected): 2/3 (66.7%)
  Effective Glosses: WOMAN, WRONG, APPLE
  Effective Mismatches:
    Position 1: LLM chose 'WRONG' but should be 'EAT'
      Available top-k predictions:
        1. wrong (65.2%)
        2. hot (8.4%)
        3. deaf (4.9%)
  Baseline BLEU: 12.75
  Model BLEU: 26.27
  BLEU Improvement: +13.52
  Baseline BERTScore: 88.68
  Model BERTScore: 91.83
  BERTScore Improvement: +3.15
  Baseline Quality: 7.45
  Model Quality: 82.66
  Quality Improvement: +75.21
  Baseline Coverage Recall: 66.7%
  Baseline Coverage Precision: 66.7%
  Baseline Coverage F1: 66.7%
  Model Coverage Recall: 66.7%
  Model Coverage Precision: 66.7%
  Model Coverage F1: 66.7%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: +0.0%
  Coverage F1 Improvement: +0.0%
  Missing Words: eating
  Hallucinated Words: wrong
  Baseline Composite: 39.30
  Model Composite: 72.04
  Composite Improvement: +32.74
  LLM Alternatives Used: 0/3
  Status: success

Entry 3:
  Glosses: MOTHER, GIVE, APPLE
  Reference: The mother will give an apple.
  Predicted: Now the mother wants an apple.
  Model Gloss Accuracy (top-1): 2/3 (66.7%)
  Top-1 Mismatches:
    Position 1: 'now' vs 'GIVE'
  Effective Gloss Accuracy (LLM-selected): 2/3 (66.7%)
  Effective Glosses: MOTHER, NOW, APPLE
  Effective Mismatches:
    Position 1: LLM chose 'NOW' but should be 'GIVE'
      Available top-k predictions:
        1. now (50.7%)
        2. give (40.0%) [CORRECT!]
        3. dog (6.1%)
  Baseline BLEU: 12.75
  Model BLEU: 22.96
  BLEU Improvement: +10.20
  Baseline BERTScore: 88.62
  Model BERTScore: 94.57
  BERTScore Improvement: +5.96
  Baseline Quality: 16.00
  Model Quality: 84.90
  Quality Improvement: +68.90
  Baseline Coverage Recall: 66.7%
  Baseline Coverage Precision: 66.7%
  Baseline Coverage F1: 66.7%
  Model Coverage Recall: 66.7%
  Model Coverage Precision: 50.0%
  Model Coverage F1: 57.1%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: -16.7%
  Coverage F1 Improvement: -9.5%
  Missing Words: give
  Hallucinated Words: now, wants
  Baseline Composite: 42.70
  Model Composite: 70.60
  Composite Improvement: +27.90
  LLM Alternatives Used: 0/3
  Status: success

Entry 4:
  Glosses: COUSIN, LIKE, CANDY
  Reference: The cousin likes candy.
  Predicted: My cousin likes candy.
  Model Gloss Accuracy (top-1): 3/3 (100.0%)
  Effective Gloss Accuracy (LLM-selected): 3/3 (100.0%)
  Effective Glosses: COUSIN, LIKE, CANDY
  Baseline BLEU: 24.84
  Model BLEU: 59.46
  BLEU Improvement: +34.62
  Baseline BERTScore: 94.17
  Model BERTScore: 99.81
  BERTScore Improvement: +5.64
  Baseline Quality: 75.88
  Model Quality: 52.56
  Quality Improvement: -23.31
  Baseline Coverage Recall: 100.0%
  Baseline Coverage Precision: 100.0%
  Baseline Coverage F1: 100.0%
  Model Coverage Recall: 100.0%
  Model Coverage Precision: 75.0%
  Model Coverage F1: 85.7%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: -25.0%
  Coverage F1 Improvement: -14.3%
  Hallucinated Words: my
  Baseline Composite: 77.91
  Model Composite: 71.33
  Composite Improvement: -6.58
  LLM Alternatives Used: 0/3
  Status: success

Entry 5:
  Glosses: DOCTOR, HELP, MAN
  Reference: The doctor is helping the man.
  Predicted: The doctor helps the man.
  Model Gloss Accuracy (top-1): 3/3 (100.0%)
  Effective Gloss Accuracy (LLM-selected): 3/3 (100.0%)
  Effective Glosses: DOCTOR, HELP, MAN
  Baseline BLEU: 12.75
  Model BLEU: 24.74
  BLEU Improvement: +11.98
  Baseline BERTScore: 90.10
  Model BERTScore: 97.90
  BERTScore Improvement: +7.80
  Baseline Quality: 59.41
  Model Quality: 77.83
  Quality Improvement: +18.43
  Baseline Coverage Recall: 100.0%
  Baseline Coverage Precision: 100.0%
  Baseline Coverage F1: 100.0%
  Model Coverage Recall: 100.0%
  Model Coverage Precision: 100.0%
  Model Coverage F1: 100.0%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: +0.0%
  Coverage F1 Improvement: +0.0%
  Baseline Composite: 68.70
  Model Composite: 79.42
  Composite Improvement: +10.73
  LLM Alternatives Used: 0/3
  Status: success

Entry 6:
  Glosses: FORGET, GRADUATION, YEAR
  Reference: I forgot my graduation year.
  Predicted: Forget about the graduation year.
  Model Gloss Accuracy (top-1): 3/3 (100.0%)
  Effective Gloss Accuracy (LLM-selected): 3/3 (100.0%)
  Effective Glosses: FORGET, GRADUATION, YEAR
  Baseline BLEU: 28.25
  Model BLEU: 21.36
  BLEU Improvement: -6.89
  Baseline BERTScore: 92.84
  Model BERTScore: 92.57
  BERTScore Improvement: -0.27
  Baseline Quality: 22.00
  Model Quality: 80.94
  Quality Improvement: +58.93
  Baseline Coverage Recall: 80.0%
  Baseline Coverage Precision: 100.0%
  Baseline Coverage F1: 88.9%
  Model Coverage Recall: 80.0%
  Model Coverage Precision: 100.0%
  Model Coverage F1: 88.9%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: +0.0%
  Coverage F1 Improvement: +0.0%
  Missing Words: my
  Baseline Composite: 53.83
  Model Composite: 76.32
  Composite Improvement: +22.49
  LLM Alternatives Used: 0/3
  Status: success

Entry 7:
  Glosses: BOOK, TABLE, NOW
  Reference: The book is on table now.
  Predicted: The book is on the computer now.
  Model Gloss Accuracy (top-1): 2/3 (66.7%)
  Top-1 Mismatches:
    Position 1: 'computer' vs 'TABLE'
  Effective Gloss Accuracy (LLM-selected): 2/3 (66.7%)
  Effective Glosses: BOOK, COMPUTER, NOW
  Effective Mismatches:
    Position 1: LLM chose 'COMPUTER' but should be 'TABLE'
      Available top-k predictions:
        1. computer (71.1%)
        2. table (27.8%) [CORRECT!]
        3. year (0.3%)
  Baseline BLEU: 12.75
  Model BLEU: 43.47
  BLEU Improvement: +30.72
  Baseline BERTScore: 90.48
  Model BERTScore: 95.11
  BERTScore Improvement: +4.63
  Baseline Quality: 56.86
  Model Quality: 94.00
  Quality Improvement: +37.14
  Baseline Coverage Recall: 66.7%
  Baseline Coverage Precision: 66.7%
  Baseline Coverage F1: 66.7%
  Model Coverage Recall: 66.7%
  Model Coverage Precision: 66.7%
  Model Coverage F1: 66.7%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: +0.0%
  Coverage F1 Improvement: +0.0%
  Missing Words: table
  Hallucinated Words: computer
  Baseline Composite: 59.42
  Model Composite: 79.81
  Composite Improvement: +20.39
  LLM Alternatives Used: 0/3
  Status: success

Entry 8:
  Glosses: CHAIR, BLACK, NOW
  Reference: The chair is black now.
  Predicted: The black chair is here now.
  Model Gloss Accuracy (top-1): 3/3 (100.0%)
  Effective Gloss Accuracy (LLM-selected): 3/3 (100.0%)
  Effective Glosses: CHAIR, BLACK, NOW
  Baseline BLEU: 32.34
  Model BLEU: 20.41
  BLEU Improvement: -11.93
  Baseline BERTScore: 93.61
  Model BERTScore: 94.40
  BERTScore Improvement: +0.79
  Baseline Quality: 55.14
  Model Quality: 82.87
  Quality Improvement: +27.73
  Baseline Coverage Recall: 100.0%
  Baseline Coverage Precision: 100.0%
  Baseline Coverage F1: 100.0%
  Model Coverage Recall: 100.0%
  Model Coverage Precision: 75.0%
  Model Coverage F1: 85.7%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: -25.0%
  Coverage F1 Improvement: -14.3%
  Hallucinated Words: here
  Baseline Composite: 70.63
  Model Composite: 76.52
  Composite Improvement: +5.89
  LLM Alternatives Used: 0/3
  Status: success

Entry 9:
  Glosses: APPLE, ORANGE, EAT
  Reference: I will eat apple or orange.
  Predicted: The apple hearing is wrong.
  Model Gloss Accuracy (top-1): 1/3 (33.3%)
  Top-1 Mismatches:
    Position 1: 'apple' vs 'ORANGE'
    Position 2: 'wrong' vs 'EAT'
  Effective Gloss Accuracy (LLM-selected): 1/3 (33.3%)
  Effective Glosses: APPLE, HEARING, WRONG
  Effective Mismatches:
    Position 1: LLM chose 'HEARING' but should be 'ORANGE'
      Available top-k predictions:
        1. apple (49.6%)
        2. hearing (18.0%)
        3. cool (6.9%)
    Position 2: LLM chose 'WRONG' but should be 'EAT'
      Available top-k predictions:
        1. wrong (65.2%)
        2. hot (8.4%)
        3. deaf (4.9%)
  Baseline BLEU: 10.12
  Model BLEU: 8.75
  BLEU Improvement: -1.38
  Baseline BERTScore: 87.62
  Model BERTScore: 86.75
  BERTScore Improvement: -0.87
  Baseline Quality: 24.13
  Model Quality: 44.03
  Quality Improvement: +19.90
  Baseline Coverage Recall: 25.0%
  Baseline Coverage Precision: 66.7%
  Baseline Coverage F1: 36.4%
  Model Coverage Recall: 50.0%
  Model Coverage Precision: 66.7%
  Model Coverage F1: 57.1%
  Coverage Recall Improvement: +25.0%
  Coverage Precision Improvement: +0.0%
  Coverage F1 Improvement: +20.8%
  Missing Words: eat, orange
  Hallucinated Words: wrong
  Baseline Composite: 37.79
  Model Composite: 50.56
  Composite Improvement: +12.77
  LLM Alternatives Used: 0/3
  Status: success

Entry 10:
  Glosses: MAN, LIKE, APPLE, NOW
  Reference: The man will like an apple now.
  Predicted: The man likes the apple now.
  Model Gloss Accuracy (top-1): 4/4 (100.0%)
  Effective Gloss Accuracy (LLM-selected): 4/4 (100.0%)
  Effective Glosses: MAN, LIKE, APPLE, NOW
  Baseline BLEU: 17.95
  Model BLEU: 19.43
  BLEU Improvement: +1.49
  Baseline BERTScore: 92.76
  Model BERTScore: 95.29
  BERTScore Improvement: +2.53
  Baseline Quality: 39.68
  Model Quality: 59.35
  Quality Improvement: +19.67
  Baseline Coverage Recall: 100.0%
  Baseline Coverage Precision: 100.0%
  Baseline Coverage F1: 100.0%
  Model Coverage Recall: 100.0%
  Model Coverage Precision: 100.0%
  Model Coverage F1: 100.0%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: +0.0%
  Coverage F1 Improvement: +0.0%
  Baseline Composite: 62.12
  Model Composite: 70.72
  Composite Improvement: +8.60
  LLM Alternatives Used: 0/4
  Status: success

Entry 11:
  Glosses: MOTHER, GIVE, BOOK, NOW
  Reference: The mother will give a book now.
  Predicted: Mother, give the book now.
  Model Gloss Accuracy (top-1): 3/4 (75.0%)
  Top-1 Mismatches:
    Position 1: 'now' vs 'GIVE'
  Effective Gloss Accuracy (LLM-selected): 4/4 (100.0%)
  Effective Glosses: MOTHER, GIVE, BOOK, NOW
  Gloss Accuracy Improvement: +25.0%
  Baseline BLEU: 16.70
  Model BLEU: 18.01
  BLEU Improvement: +1.31
  Baseline BERTScore: 87.42
  Model BERTScore: 92.55
  BERTScore Improvement: +5.12
  Baseline Quality: 49.20
  Model Quality: 85.02
  Quality Improvement: +35.83
  Baseline Coverage Recall: 75.0%
  Baseline Coverage Precision: 100.0%
  Baseline Coverage F1: 85.7%
  Model Coverage Recall: 100.0%
  Model Coverage Precision: 100.0%
  Model Coverage F1: 100.0%
  Coverage Recall Improvement: +25.0%
  Coverage Precision Improvement: +0.0%
  Coverage F1 Improvement: +14.3%
  Baseline Composite: 61.10
  Model Composite: 80.22
  Composite Improvement: +19.12
  LLM Alternatives Used: 0/4
  Status: success

Entry 12:
  Glosses: COUSIN, LIKE, CANDY, MANY
  Reference: The cousin likes many candies.
  Predicted: My cousin likes many candy.
  Model Gloss Accuracy (top-1): 4/4 (100.0%)
  Effective Gloss Accuracy (LLM-selected): 4/4 (100.0%)
  Effective Glosses: COUSIN, LIKE, CANDY, MANY
  Baseline BLEU: 14.79
  Model BLEU: 39.76
  BLEU Improvement: +24.97
  Baseline BERTScore: 91.45
  Model BERTScore: 98.35
  BERTScore Improvement: +6.90
  Baseline Quality: 38.48
  Model Quality: 29.73
  Quality Improvement: -8.75
  Baseline Coverage Recall: 100.0%
  Baseline Coverage Precision: 100.0%
  Baseline Coverage F1: 100.0%
  Model Coverage Recall: 100.0%
  Model Coverage Precision: 80.0%
  Model Coverage F1: 88.9%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: -20.0%
  Coverage F1 Improvement: -11.1%
  Hallucinated Words: my
  Baseline Composite: 60.90
  Model Composite: 59.75
  Composite Improvement: -1.15
  LLM Alternatives Used: 0/4
  Status: success

Entry 13:
  Glosses: DOCTOR, HELP, MAN, NOW
  Reference: The doctor will help man now.
  Predicted: The doctor will help the man now.
  Model Gloss Accuracy (top-1): 4/4 (100.0%)
  Effective Gloss Accuracy (LLM-selected): 4/4 (100.0%)
  Effective Glosses: DOCTOR, HELP, MAN, NOW
  Baseline BLEU: 38.75
  Model BLEU: 48.89
  BLEU Improvement: +10.14
  Baseline BERTScore: 93.50
  Model BERTScore: 97.09
  BERTScore Improvement: +3.59
  Baseline Quality: 55.54
  Model Quality: 84.13
  Quality Improvement: +28.58
  Baseline Coverage Recall: 100.0%
  Baseline Coverage Precision: 100.0%
  Baseline Coverage F1: 100.0%
  Model Coverage Recall: 100.0%
  Model Coverage Precision: 100.0%
  Model Coverage F1: 100.0%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: +0.0%
  Coverage F1 Improvement: +0.0%
  Baseline Composite: 71.73
  Model Composite: 85.40
  Composite Improvement: +13.67
  LLM Alternatives Used: 0/4
  Status: success

Entry 14:
  Glosses: COMPUTER, COOL, NOW, YES, NO
  Reference: The computer is cool now, yes or no?
  Predicted: The computer is cool now, yes or no?
  Model Gloss Accuracy (top-1): 5/5 (100.0%)
  Effective Gloss Accuracy (LLM-selected): 5/5 (100.0%)
  Effective Glosses: COMPUTER, COOL, NOW, YES, NO
  Baseline BLEU: 24.80
  Model BLEU: 100.00
  BLEU Improvement: +75.20
  Baseline BERTScore: 90.87
  Model BERTScore: 100.00
  BERTScore Improvement: +9.13
  Baseline Quality: 28.86
  Model Quality: 87.33
  Quality Improvement: +58.47
  Baseline Coverage Recall: 100.0%
  Baseline Coverage Precision: 100.0%
  Baseline Coverage F1: 100.0%
  Model Coverage Recall: 100.0%
  Model Coverage Precision: 100.0%
  Model Coverage F1: 100.0%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: +0.0%
  Coverage F1 Improvement: +0.0%
  Baseline Composite: 58.44
  Model Composite: 94.93
  Composite Improvement: +36.50
  LLM Alternatives Used: 0/5
  Status: success

Entry 15:
  Glosses: CHAIR, BLACK, NOW, FINE, YES
  Reference: The black chair is fine now, yes?
  Predicted: Now the black chair is like yes.
  Model Gloss Accuracy (top-1): 4/5 (80.0%)
  Top-1 Mismatches:
    Position 3: 'like' vs 'FINE'
  Effective Gloss Accuracy (LLM-selected): 4/5 (80.0%)
  Effective Glosses: CHAIR, BLACK, NOW, LIKE, YES
  Effective Mismatches:
    Position 3: LLM chose 'LIKE' but should be 'FINE'
      Available top-k predictions:
        1. like (90.4%)
        2. fine (6.5%) [CORRECT!]
        3. walk (1.7%)
  Baseline BLEU: 10.13
  Model BLEU: 45.50
  BLEU Improvement: +35.37
  Baseline BERTScore: 89.62
  Model BERTScore: 89.43
  BERTScore Improvement: -0.19
  Baseline Quality: 34.63
  Model Quality: 68.70
  Quality Improvement: +34.07
  Baseline Coverage Recall: 80.0%
  Baseline Coverage Precision: 80.0%
  Baseline Coverage F1: 80.0%
  Model Coverage Recall: 80.0%
  Model Coverage Precision: 80.0%
  Model Coverage F1: 80.0%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: +0.0%
  Coverage F1 Improvement: +0.0%
  Missing Words: fine
  Hallucinated Words: like
  Baseline Composite: 53.30
  Model Composite: 72.19
  Composite Improvement: +18.90
  LLM Alternatives Used: 0/5
  Status: success

Entry 16:
  Glosses: APPLE, ORANGE, EAT, NOW, LIKE, YES, NO
  Reference: I will eat apple or orange now, do you like it, yes or no?
  Predicted: Hearing the apple is wrong now, like yes or no?
  Model Gloss Accuracy (top-1): 5/7 (71.4%)
  Top-1 Mismatches:
    Position 1: 'apple' vs 'ORANGE'
    Position 2: 'wrong' vs 'EAT'
  Effective Gloss Accuracy (LLM-selected): 5/7 (71.4%)
  Effective Glosses: APPLE, HEARING, WRONG, NOW, LIKE, YES, NO
  Effective Mismatches:
    Position 1: LLM chose 'HEARING' but should be 'ORANGE'
      Available top-k predictions:
        1. apple (49.6%)
        2. hearing (18.0%)
        3. cool (6.9%)
    Position 2: LLM chose 'WRONG' but should be 'EAT'
      Available top-k predictions:
        1. wrong (65.2%)
        2. hot (8.4%)
        3. deaf (4.9%)
  Baseline BLEU: 3.61
  Model BLEU: 12.45
  BLEU Improvement: +8.84
  Baseline BERTScore: 86.50
  Model BERTScore: 88.09
  BERTScore Improvement: +1.59
  Baseline Quality: 34.19
  Model Quality: 82.03
  Quality Improvement: +47.84
  Baseline Coverage Recall: 60.0%
  Baseline Coverage Precision: 85.7%
  Baseline Coverage F1: 70.6%
  Model Coverage Recall: 60.0%
  Model Coverage Precision: 85.7%
  Model Coverage F1: 70.6%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: +0.0%
  Coverage F1 Improvement: +0.0%
  Missing Words: eat, orange, you, it
  Hallucinated Words: wrong
  Baseline Composite: 49.17
  Model Composite: 69.94
  Composite Improvement: +20.78
  LLM Alternatives Used: 0/7
  Status: success

Entry 17:
  Glosses: MAN, LIKE, APPLE, NOW, WOMAN, LIKE, ORANGE
  Reference: The man likes apple now, but the woman likes orange.
  Predicted: The man and woman like the apple now like the apple.
  Model Gloss Accuracy (top-1): 6/7 (85.7%)
  Top-1 Mismatches:
    Position 6: 'apple' vs 'ORANGE'
  Effective Gloss Accuracy (LLM-selected): 6/7 (85.7%)
  Effective Glosses: MAN, LIKE, APPLE, NOW, WOMAN, LIKE, APPLE
  Effective Mismatches:
    Position 6: LLM chose 'APPLE' but should be 'ORANGE'
      Available top-k predictions:
        1. apple (49.6%)
        2. hearing (18.0%)
        3. cool (6.9%)
  Baseline BLEU: 10.18
  Model BLEU: 11.73
  BLEU Improvement: +1.56
  Baseline BERTScore: 91.26
  Model BERTScore: 90.61
  BERTScore Improvement: -0.65
  Baseline Quality: 50.65
  Model Quality: 85.50
  Quality Improvement: +34.84
  Baseline Coverage Recall: 85.7%
  Baseline Coverage Precision: 100.0%
  Baseline Coverage F1: 92.3%
  Model Coverage Recall: 85.7%
  Model Coverage Precision: 100.0%
  Model Coverage F1: 92.3%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: +0.0%
  Coverage F1 Improvement: +0.0%
  Missing Words: orange
  Baseline Composite: 63.12
  Model Composite: 77.16
  Composite Improvement: +14.04
  LLM Alternatives Used: 0/7
  Status: success

Entry 18:
  Glosses: HALLOWEEN, BEFORE, THANKSGIVING
  Reference: Halloween is before Thanksgiving.
  Predicted: Halloween is before Thanksgiving.
  Model Gloss Accuracy (top-1): 3/3 (100.0%)
  Effective Gloss Accuracy (LLM-selected): 3/3 (100.0%)
  Effective Glosses: HALLOWEEN, BEFORE, THANKSGIVING
  Baseline BLEU: 45.14
  Model BLEU: 100.00
  BLEU Improvement: +54.86
  Baseline BERTScore: 89.89
  Model BERTScore: 100.00
  BERTScore Improvement: +10.11
  Baseline Quality: 57.25
  Model Quality: 63.47
  Quality Improvement: +6.21
  Baseline Coverage Recall: 100.0%
  Baseline Coverage Precision: 100.0%
  Baseline Coverage F1: 100.0%
  Model Coverage Recall: 100.0%
  Model Coverage Precision: 100.0%
  Model Coverage F1: 100.0%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: +0.0%
  Coverage F1 Improvement: +0.0%
  Baseline Composite: 72.65
  Model Composite: 85.39
  Composite Improvement: +12.74
  LLM Alternatives Used: 0/3
  Status: success

Entry 19:
  Glosses: MAN, KISS, WOMAN, THANKSGIVING
  Reference: The man kissed the woman on Thanksgiving.
  Predicted: The man gave a kiss to the woman on Thanksgiving.
  Model Gloss Accuracy (top-1): 4/4 (100.0%)
  Effective Gloss Accuracy (LLM-selected): 4/4 (100.0%)
  Effective Glosses: MAN, KISS, WOMAN, THANKSGIVING
  Baseline BLEU: 9.93
  Model BLEU: 31.24
  BLEU Improvement: +21.31
  Baseline BERTScore: 91.59
  Model BERTScore: 98.45
  BERTScore Improvement: +6.86
  Baseline Quality: 21.03
  Model Quality: 94.13
  Quality Improvement: +73.10
  Baseline Coverage Recall: 100.0%
  Baseline Coverage Precision: 100.0%
  Baseline Coverage F1: 100.0%
  Model Coverage Recall: 100.0%
  Model Coverage Precision: 80.0%
  Model Coverage F1: 88.9%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: -20.0%
  Coverage F1 Improvement: -11.1%
  Hallucinated Words: gave
  Baseline Composite: 53.22
  Model Composite: 84.25
  Composite Improvement: +31.03
  LLM Alternatives Used: 0/4
  Status: success

Entry 20:
  Glosses: DOG, LIKE, BATH
  Reference: The dog likes a bath.
  Predicted: The dog likes a bath.
  Model Gloss Accuracy (top-1): 3/3 (100.0%)
  Effective Gloss Accuracy (LLM-selected): 3/3 (100.0%)
  Effective Glosses: DOG, LIKE, BATH
  Baseline BLEU: 17.80
  Model BLEU: 100.00
  BLEU Improvement: +82.20
  Baseline BERTScore: 92.84
  Model BERTScore: 100.00
  BERTScore Improvement: +7.16
  Baseline Quality: 14.36
  Model Quality: 61.72
  Quality Improvement: +47.36
  Baseline Coverage Recall: 100.0%
  Baseline Coverage Precision: 100.0%
  Baseline Coverage F1: 100.0%
  Model Coverage Recall: 100.0%
  Model Coverage Precision: 100.0%
  Model Coverage F1: 100.0%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: +0.0%
  Coverage F1 Improvement: +0.0%
  Baseline Composite: 51.98
  Model Composite: 84.69
  Composite Improvement: +32.70
  LLM Alternatives Used: 0/3
  Status: success

Entry 21:
  Glosses: DOCTOR, GIVE, APPLE
  Reference: The doctor is giving an apple.
  Predicted: The doctor will give an apple.
  Model Gloss Accuracy (top-1): 2/3 (66.7%)
  Top-1 Mismatches:
    Position 1: 'now' vs 'GIVE'
  Effective Gloss Accuracy (LLM-selected): 3/3 (100.0%)
  Effective Glosses: DOCTOR, GIVE, APPLE
  Gloss Accuracy Improvement: +33.3%
  Baseline BLEU: 12.75
  Model BLEU: 22.96
  BLEU Improvement: +10.20
  Baseline BERTScore: 88.83
  Model BERTScore: 97.10
  BERTScore Improvement: +8.28
  Baseline Quality: 14.09
  Model Quality: 74.98
  Quality Improvement: +60.88
  Baseline Coverage Recall: 66.7%
  Baseline Coverage Precision: 66.7%
  Baseline Coverage F1: 66.7%
  Model Coverage Recall: 66.7%
  Model Coverage Precision: 66.7%
  Model Coverage F1: 66.7%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: +0.0%
  Coverage F1 Improvement: +0.0%
  Missing Words: giving
  Hallucinated Words: give
  Baseline Composite: 41.98
  Model Composite: 69.52
  Composite Improvement: +27.54
  LLM Alternatives Used: 1/3
    Position 1: Used 'give' (top-2, 40.0%) instead of 'now' (top-1, 50.7%)
  Status: success

Entry 22:
  Glosses: MOTHER, GIVE, APPLE, NOW
  Reference: The mother is giving an apple now.
  Predicted: Mother, give the apple now.
  Model Gloss Accuracy (top-1): 3/4 (75.0%)
  Top-1 Mismatches:
    Position 1: 'now' vs 'GIVE'
  Effective Gloss Accuracy (LLM-selected): 4/4 (100.0%)
  Effective Glosses: MOTHER, GIVE, APPLE, NOW
  Gloss Accuracy Improvement: +25.0%
  Baseline BLEU: 16.70
  Model BLEU: 17.03
  BLEU Improvement: +0.33
  Baseline BERTScore: 89.18
  Model BERTScore: 92.66
  BERTScore Improvement: +3.48
  Baseline Quality: 20.61
  Model Quality: 79.11
  Quality Improvement: +58.50
  Baseline Coverage Recall: 75.0%
  Baseline Coverage Precision: 100.0%
  Baseline Coverage F1: 85.7%
  Model Coverage Recall: 75.0%
  Model Coverage Precision: 75.0%
  Model Coverage F1: 75.0%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: -25.0%
  Coverage F1 Improvement: -10.7%
  Missing Words: giving
  Hallucinated Words: give
  Baseline Composite: 50.02
  Model Composite: 71.48
  Composite Improvement: +21.47
  LLM Alternatives Used: 0/4
  Status: success

Entry 23:
  Glosses: WHO, LIKE, BLACK, DOG
  Reference: Who likes the black dog?
  Predicted: Who likes the black dog?
  Model Gloss Accuracy (top-1): 4/4 (100.0%)
  Effective Gloss Accuracy (LLM-selected): 4/4 (100.0%)
  Effective Glosses: WHO, LIKE, BLACK, DOG
  Baseline BLEU: 27.53
  Model BLEU: 100.00
  BLEU Improvement: +72.47
  Baseline BERTScore: 93.24
  Model BERTScore: 100.00
  BERTScore Improvement: +6.76
  Baseline Quality: 47.28
  Model Quality: 80.35
  Quality Improvement: +33.07
  Baseline Coverage Recall: 100.0%
  Baseline Coverage Precision: 100.0%
  Baseline Coverage F1: 100.0%
  Model Coverage Recall: 100.0%
  Model Coverage Precision: 100.0%
  Model Coverage F1: 100.0%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: +0.0%
  Coverage F1 Improvement: +0.0%
  Baseline Composite: 66.69
  Model Composite: 92.14
  Composite Improvement: +25.45
  LLM Alternatives Used: 0/4
  Status: success

Entry 24:
  Glosses: COMPUTER, COOL, MAN, LIKE, ALL
  Reference: The cool man likes all computers.
  Predicted: The cool man like computer all.
  Model Gloss Accuracy (top-1): 5/5 (100.0%)
  Effective Gloss Accuracy (LLM-selected): 5/5 (100.0%)
  Effective Glosses: COMPUTER, COOL, MAN, LIKE, ALL
  Baseline BLEU: 19.36
  Model BLEU: 32.47
  BLEU Improvement: +13.11
  Baseline BERTScore: 90.50
  Model BERTScore: 91.99
  BERTScore Improvement: +1.49
  Baseline Quality: 42.26
  Model Quality: 8.99
  Quality Improvement: -33.27
  Baseline Coverage Recall: 100.0%
  Baseline Coverage Precision: 100.0%
  Baseline Coverage F1: 100.0%
  Model Coverage Recall: 100.0%
  Model Coverage Precision: 100.0%
  Model Coverage F1: 100.0%
  Coverage Recall Improvement: +0.0%
  Coverage Precision Improvement: +0.0%
  Coverage F1 Improvement: +0.0%
  Baseline Composite: 62.91
  Model Composite: 51.86
  Composite Improvement: -11.04
  LLM Alternatives Used: 0/5
  Status: success

Entry 25:
  Glosses: MOTHER, GIVE, APPLE, FORGET, DRINK, NOW
  Reference: The mother is giving an apple, but forgot to drink now.
  Predicted: Mother, give the apple to forget, forget now.
  Model Gloss Accuracy (top-1): 5/6 (83.3%)
  Top-1 Mismatches:
    Position 1: 'now' vs 'GIVE'
  Effective Gloss Accuracy (LLM-selected): 5/6 (83.3%)
  Effective Glosses: MOTHER, GIVE, APPLE, FORGET, FORGET, NOW
  Effective Mismatches:
    Position 4: LLM chose 'FORGET' but should be 'DRINK'
      Available top-k predictions:
        1. drink (64.5%) [CORRECT!]
        2. forget (21.5%)
        3. cousin (9.1%)
  Baseline BLEU: 8.39
  Model BLEU: 5.68
  BLEU Improvement: -2.71
  Baseline BERTScore: 87.66
  Model BERTScore: 89.25
  BERTScore Improvement: +1.59
  Baseline Quality: 2.31
  Model Quality: 81.19
  Quality Improvement: +78.88
  Baseline Coverage Recall: 83.3%
  Baseline Coverage Precision: 100.0%
  Baseline Coverage F1: 90.9%
  Model Coverage Recall: 66.7%
  Model Coverage Precision: 83.3%
  Model Coverage F1: 74.1%
  Coverage Recall Improvement: -16.7%
  Coverage Precision Improvement: -16.7%
  Coverage F1 Improvement: -16.8%
  Missing Words: giving, drink
  Hallucinated Words: give
  Baseline Composite: 42.44
  Model Composite: 69.69
  Composite Improvement: +27.25
  LLM Alternatives Used: 1/6
    Position 4: Used 'forget' (top-2, 21.5%) instead of 'drink' (top-1, 64.5%)
  Status: success
